var documenterSearchIndex = {"docs":
[{"location":"manual/optimal_trajectories/#Choosing-Optimal-Numbers-of-Trajectories","page":"Choosing Optimal Numbers of Trajectories","title":"Choosing Optimal Numbers of Trajectories","text":"","category":"section"},{"location":"manual/optimal_trajectories/","page":"Choosing Optimal Numbers of Trajectories","title":"Choosing Optimal Numbers of Trajectories","text":"There is a balance between two things for choosing the number of trajectories:","category":"page"},{"location":"manual/optimal_trajectories/","page":"Choosing Optimal Numbers of Trajectories","title":"Choosing Optimal Numbers of Trajectories","text":"The number of trajectories needs to be high enough that the work per kernel is sufficient to overcome the kernel call cost.\nMore trajectories means that every trajectory will need more time steps since the adaptivity syncs all solves.","category":"page"},{"location":"manual/optimal_trajectories/","page":"Choosing Optimal Numbers of Trajectories","title":"Choosing Optimal Numbers of Trajectories","text":"From our testing, the balance is found at around 10,000 trajectories being optimal for EnsembleGPUArray, since it has higher kernel call costs because every internal operation of the ODE solver requires a kernel call. Thus for larger sets of trajectories, use a batch size of 10,000. Of course, benchmark for yourself on your own setup as all GPUs are different.","category":"page"},{"location":"manual/optimal_trajectories/","page":"Choosing Optimal Numbers of Trajectories","title":"Choosing Optimal Numbers of Trajectories","text":"On the other hand, EnsembleGPUKernel fuses the entire GPU solve into a single kernel, greatly reducing the kernel call cost. This means longer or more expensive ODE solves will require even less of a percentage of time kernel launching, making the cutoff much smaller. We see some cases with around 100 ODEs being viable with EnsembleGPUKernel. Again, this is highly dependent on the ODE and the chosen GPU and thus one will need to benchmark to get accurate numbers for their system, this is merely a ballpark estimate.","category":"page"},{"location":"tutorials/multigpu/#Setting-Up-Multi-GPU-Parallel-Parameter-Sweeps","page":"Setting Up Multi-GPU Parallel Parameter Sweeps","title":"Setting Up Multi-GPU Parallel Parameter Sweeps","text":"","category":"section"},{"location":"tutorials/multigpu/","page":"Setting Up Multi-GPU Parallel Parameter Sweeps","title":"Setting Up Multi-GPU Parallel Parameter Sweeps","text":"note: Note\nThis tutorial assumes one already has familarity with EnsembleGPUArray and EnsembleGPUKernel. Please see the Lorenz equation tutorial before reading this tutorial!","category":"page"},{"location":"tutorials/multigpu/","page":"Setting Up Multi-GPU Parallel Parameter Sweeps","title":"Setting Up Multi-GPU Parallel Parameter Sweeps","text":"In this tutorial we will show how to increase the number of trajectories that can be computed in parallel by setting up and using a multi-GPU solve. For this, we will setup one Julia process for each GPU and let the internal pmap system of EnsembleGPUArray parallelize the system across all of our GPUs. Let's dig in.","category":"page"},{"location":"tutorials/multigpu/#Setting-Up-a-Multi-GPU-Julia-Environment","page":"Setting Up Multi-GPU Parallel Parameter Sweeps","title":"Setting Up a Multi-GPU Julia Environment","text":"","category":"section"},{"location":"tutorials/multigpu/","page":"Setting Up Multi-GPU Parallel Parameter Sweeps","title":"Setting Up Multi-GPU Parallel Parameter Sweeps","text":"To setup a multi-GPU environment, first setup a processes such that every process has a different GPU. For example:","category":"page"},{"location":"tutorials/multigpu/","page":"Setting Up Multi-GPU Parallel Parameter Sweeps","title":"Setting Up Multi-GPU Parallel Parameter Sweeps","text":"# Setup processes with different CUDA devices\nusing Distributed\naddprocs(numgpus)\nimport CUDA\n\nlet gpuworkers = asyncmap(collect(zip(workers(), CUDA.devices()))) do (p, d)\n  remotecall_wait(CUDA.device!, p, d)\n  p\nend","category":"page"},{"location":"tutorials/multigpu/","page":"Setting Up Multi-GPU Parallel Parameter Sweeps","title":"Setting Up Multi-GPU Parallel Parameter Sweeps","text":"Then setup the calls to work with distributed processes:","category":"page"},{"location":"tutorials/multigpu/","page":"Setting Up Multi-GPU Parallel Parameter Sweeps","title":"Setting Up Multi-GPU Parallel Parameter Sweeps","text":"@everywhere using DiffEqGPU, CUDA, OrdinaryDiffEq, Test, Random\n\n@everywhere begin\n    function lorenz_distributed(du,u,p,t)\n        du[1] = p[1]*(u[2]-u[1])\n        du[2] = u[1]*(p[2]-u[3]) - u[2]\n        du[3] = u[1]*u[2] - p[3]*u[3]\n    end\n    CUDA.allowscalar(false)\n    u0 = Float32[1.0;0.0;0.0]\n    tspan = (0.0f0,100.0f0)\n    p = [10.0f0,28.0f0,8/3f0]\n    Random.seed!(1)\n    function prob_func_distributed(prob,i,repeat)\n        remake(prob,p=rand(3).*p)\n    end\nend","category":"page"},{"location":"tutorials/multigpu/","page":"Setting Up Multi-GPU Parallel Parameter Sweeps","title":"Setting Up Multi-GPU Parallel Parameter Sweeps","text":"Now each batch will run on separate GPUs. Thus we need to use the batch_size keyword argument from the Ensemble interface to ensure there are multiple batches. Let's solve 40,000 trajectories, batching 10,000 trajectories at a time:","category":"page"},{"location":"tutorials/multigpu/","page":"Setting Up Multi-GPU Parallel Parameter Sweeps","title":"Setting Up Multi-GPU Parallel Parameter Sweeps","text":"prob = ODEProblem(lorenz_distributed,u0,tspan,p)\nmonteprob = EnsembleProblem(prob, prob_func = prob_func_distributed)\n\n@time sol2 = solve(monteprob,Tsit5(),EnsembleGPUArray(),trajectories=40_000,\n                                                 batch_size=10_000,saveat=1.0f0)","category":"page"},{"location":"tutorials/multigpu/","page":"Setting Up Multi-GPU Parallel Parameter Sweeps","title":"Setting Up Multi-GPU Parallel Parameter Sweeps","text":"This will pmap over the batches, and thus if you have 4 processes each with a GPU, each batch of 10,000 trajectories will be run simultaneously. If you have two processes with two GPUs, this will do two sets of 10,000 at a time.","category":"page"},{"location":"tutorials/multigpu/#Example-Multi-GPU-Script","page":"Setting Up Multi-GPU Parallel Parameter Sweeps","title":"Example Multi-GPU Script","text":"","category":"section"},{"location":"tutorials/multigpu/","page":"Setting Up Multi-GPU Parallel Parameter Sweeps","title":"Setting Up Multi-GPU Parallel Parameter Sweeps","text":"In this example we know we have a 2-GPU system (1 eGPU), and we split the work across the two by directly defining the devices on the two worker processes:","category":"page"},{"location":"tutorials/multigpu/","page":"Setting Up Multi-GPU Parallel Parameter Sweeps","title":"Setting Up Multi-GPU Parallel Parameter Sweeps","text":"using DiffEqGPU, CUDA, OrdinaryDiffEq, Test\nCUDA.device!(0)\n\nusing Distributed\naddprocs(2)\n@everywhere using DiffEqGPU, CUDA, OrdinaryDiffEq, Test, Random\n\n@everywhere begin\n    function lorenz_distributed(du,u,p,t)\n        du[1] = p[1]*(u[2]-u[1])\n        du[2] = u[1]*(p[2]-u[3]) - u[2]\n        du[3] = u[1]*u[2] - p[3]*u[3]\n    end\n    CUDA.allowscalar(false)\n    u0 = Float32[1.0;0.0;0.0]\n    tspan = (0.0f0,100.0f0)\n    p = [10.0f0,28.0f0,8/3f0]\n    Random.seed!(1)\n    pre_p_distributed = [rand(Float32,3) for i in 1:100_000]\n    function prob_func_distributed(prob,i,repeat)\n        remake(prob,p=pre_p_distributed[i].*p)\n    end\nend\n\n@sync begin\n    @spawnat 2 begin\n        CUDA.allowscalar(false)\n        CUDA.device!(0)\n    end\n    @spawnat 3 begin\n        CUDA.allowscalar(false)\n        CUDA.device!(1)\n    end\nend\n\nCUDA.allowscalar(false)\nprob = ODEProblem(lorenz_distributed,u0,tspan,p)\nmonteprob = EnsembleProblem(prob, prob_func = prob_func_distributed)\n\n@time sol = solve(monteprob,Tsit5(),EnsembleGPUArray(),trajectories=100_000,\n                                             batch_size=50_000,saveat=1.0f0)","category":"page"},{"location":"tutorials/parallel_callbacks/#Massively-Parallel-ODE-Solving-with-Event-Handling-and-Callbacks","page":"Massively Parallel ODE Solving with Event Handling and Callbacks","title":"Massively Parallel ODE Solving with Event Handling and Callbacks","text":"","category":"section"},{"location":"tutorials/parallel_callbacks/","page":"Massively Parallel ODE Solving with Event Handling and Callbacks","title":"Massively Parallel ODE Solving with Event Handling and Callbacks","text":"using DiffEqGPU, StaticArrays, OrdinaryDiffEq\nfunction f(u, p, t)\n    du1 = -u[1]\n    return SVector{1}(du1)\nend\n\nu0 = @SVector [10.0f0]\nprob = ODEProblem{false}(f, u0, (0.0f0, 10.0f0))\nprob_func = (prob, i, repeat) -> remake(prob, p = prob.p)\nmonteprob = EnsembleProblem(prob, safetycopy = false)\n\ncondition(u, t, integrator) = t == 4.0f0\naffect!(integrator) = integrator.u += @SVector[10.0f0]\n\ngpu_cb = DiscreteCallback(condition, affect!; save_positions = (false, false))\n\nsol = solve(monteprob, GPUTsit5(), EnsembleGPUKernel(),\n            trajectories = 10,\n            adaptive = false, dt = 0.01f0, callback = gpu_cb, merge_callbacks = true,\n            tstops = [4.0f0])","category":"page"},{"location":"manual/ensemblegpukernel/#EnsembleGPUKernel","page":"EnsembleGPUKernel","title":"EnsembleGPUKernel","text":"","category":"section"},{"location":"manual/ensemblegpukernel/#API","page":"EnsembleGPUKernel","title":"API","text":"","category":"section"},{"location":"manual/ensemblegpukernel/","page":"EnsembleGPUKernel","title":"EnsembleGPUKernel","text":"EnsembleGPUKernel","category":"page"},{"location":"manual/ensemblegpukernel/#DiffEqGPU.EnsembleGPUKernel","page":"EnsembleGPUKernel","title":"DiffEqGPU.EnsembleGPUKernel","text":"EnsembleGPUKernel(cpu_offload = 0.2)\n\nA massively-paralel ensembling algorithm which generates a unique GPU kernel for the entire ODE which is then executed. This leads to a very low overhead GPU code generation, but imparts some extra limitations on the use.\n\nPositional Arguments\n\ncpu_offload: the percentage of trajectories to offload to the CPU. Default is 0.2 or 20% of trajectories.\n\nLimitations\n\nNot all standard Julia f functions are allowed. Only Julia f functions which are capable of being compiled into a GPU kernel are allowed. This notably means that certain features of Julia can cause issues inside of a kernel, like:\nAllocating memory (building arrays)\nLinear algebra (anything that calls BLAS)\nBroadcast\nOnly out-of-place f definitions are allowed. Coupled with the requirement of not allowing for memory allocations, this means that the ODE must be defined with StaticArray initial conditions.\nOnly specific ODE solvers are allowed. This includes:\nGPUTsit5\nGPUVern7\nGPUVern9\nTo use multiple GPUs over clusters, one must manually setup one process per GPU. See the multi-GPU tutorial for more details.\n\nExample\n\nusing DiffEqGPU, OrdinaryDiffEq, StaticArrays\n\nfunction lorenz(u, p, t)\n    σ = p[1]\n    ρ = p[2]\n    β = p[3]\n    du1 = σ * (u[2] - u[1])\n    du2 = u[1] * (ρ - u[3]) - u[2]\n    du3 = u[1] * u[2] - β * u[3]\n    return SVector{3}(du1, du2, du3)\nend\n\nu0 = @SVector [1.0f0; 0.0f0; 0.0f0]\ntspan = (0.0f0, 10.0f0)\np = @SVector [10.0f0, 28.0f0, 8 / 3.0f0]\nprob = ODEProblem{false}(lorenz, u0, tspan, p)\nprob_func = (prob, i, repeat) -> remake(prob, p = (@SVector rand(Float32, 3)).*p)\nmonteprob = EnsembleProblem(prob, prob_func = prob_func, safetycopy = false)\n\n@time sol = solve(monteprob, GPUTsit5(), EnsembleGPUKernel(), trajectories = 10_000, adaptive = false, dt = 0.1f0)\n\n\n\n\n\n","category":"type"},{"location":"manual/ensemblegpukernel/#Specialized-Solvers","page":"EnsembleGPUKernel","title":"Specialized Solvers","text":"","category":"section"},{"location":"manual/ensemblegpukernel/","page":"EnsembleGPUKernel","title":"EnsembleGPUKernel","text":"GPUTsit5\nGPUVern7\nGPUVern9","category":"page"},{"location":"manual/ensemblegpukernel/#DiffEqGPU.GPUTsit5","page":"EnsembleGPUKernel","title":"DiffEqGPU.GPUTsit5","text":"GPUTsit5()\n\nA specialized implementation of the 5th order Tsit5 method specifically for kernel generation with EnsembleGPUKernel. For a similar CPU implementation, see SimpleATsit5 from SimpleDiffEq.jl\n\n\n\n\n\n","category":"type"},{"location":"manual/ensemblegpukernel/#DiffEqGPU.GPUVern7","page":"EnsembleGPUKernel","title":"DiffEqGPU.GPUVern7","text":"GPUVern7()\n\nA specialized implementation of the 7th order GPUVern7 method specifically for kernel generation with EnsembleGPUKernel.\n\n\n\n\n\n","category":"type"},{"location":"manual/ensemblegpukernel/#DiffEqGPU.GPUVern9","page":"EnsembleGPUKernel","title":"DiffEqGPU.GPUVern9","text":"GPUVern9()\n\nA specialized implementation of the 9th order GPUVern9 method specifically for kernel generation with EnsembleGPUKernel.\n\n\n\n\n\n","category":"type"},{"location":"tutorials/gpu_ensemble_basic/#lorenz","page":"Massively Data-Parallel ODE Solving the Lorenz Equation","title":"Massively Data-Parallel ODE Solving the Lorenz Equation","text":"","category":"section"},{"location":"tutorials/gpu_ensemble_basic/","page":"Massively Data-Parallel ODE Solving the Lorenz Equation","title":"Massively Data-Parallel ODE Solving the Lorenz Equation","text":"For example, the following solves the Lorenz equation with 10,000 separate random parameters on the GPU:","category":"page"},{"location":"tutorials/gpu_ensemble_basic/","page":"Massively Data-Parallel ODE Solving the Lorenz Equation","title":"Massively Data-Parallel ODE Solving the Lorenz Equation","text":"using DiffEqGPU, OrdinaryDiffEq\nfunction lorenz(du,u,p,t)\n    du[1] = p[1]*(u[2]-u[1])\n    du[2] = u[1]*(p[2]-u[3]) - u[2]\n    du[3] = u[1]*u[2] - p[3]*u[3]\nend\n\nu0 = Float32[1.0;0.0;0.0]\ntspan = (0.0f0,100.0f0)\np = [10.0f0,28.0f0,8/3f0]\nprob = ODEProblem(lorenz,u0,tspan,p)\nprob_func = (prob,i,repeat) -> remake(prob,p=rand(Float32,3).*p)\nmonteprob = EnsembleProblem(prob, prob_func = prob_func, safetycopy=false)\n@time sol = solve(monteprob,Tsit5(),EnsembleGPUArray(),trajectories=10_000,saveat=1.0f0);\n@time sol = solve(monteprob,Tsit5(),EnsembleGPUArray(),trajectories=10_000,saveat=1.0f0);","category":"page"},{"location":"tutorials/gpu_ensemble_basic/","page":"Massively Data-Parallel ODE Solving the Lorenz Equation","title":"Massively Data-Parallel ODE Solving the Lorenz Equation","text":"using DiffEqGPU, OrdinaryDiffEq, StaticArrays\n\nfunction lorenz(u, p, t)\n    σ = p[1]\n    ρ = p[2]\n    β = p[3]\n    du1 = σ * (u[2] - u[1])\n    du2 = u[1] * (ρ - u[3]) - u[2]\n    du3 = u[1] * u[2] - β * u[3]\n    return SVector{3}(du1, du2, du3)\nend\n\nu0 = @SVector [1.0f0; 0.0f0; 0.0f0]\ntspan = (0.0f0, 10.0f0)\np = @SVector [10.0f0, 28.0f0, 8 / 3.0f0]\nprob = ODEProblem{false}(lorenz, u0, tspan, p)\nprob_func = (prob, i, repeat) -> remake(prob, p = (@SVector rand(Float32, 3)).*p)\nmonteprob = EnsembleProblem(prob, prob_func = prob_func, safetycopy = false)\n\n@time sol = solve(monteprob, GPUTsit5(), EnsembleGPUKernel(), trajectories = 10_000, adaptive = false, dt = 0.1f0);\n\n@time sol = solve(monteprob, GPUTsit5(), EnsembleGPUKernel(), trajectories = 10_000, adaptive = false, dt = 0.1f0);","category":"page"},{"location":"tutorials/gpu_ensemble_basic/#Using-Stiff-ODE-Solvers-with-EnsembleGPUArray","page":"Massively Data-Parallel ODE Solving the Lorenz Equation","title":"Using Stiff ODE Solvers with EnsembleGPUArray","text":"","category":"section"},{"location":"tutorials/gpu_ensemble_basic/","page":"Massively Data-Parallel ODE Solving the Lorenz Equation","title":"Massively Data-Parallel ODE Solving the Lorenz Equation","text":"function lorenz_jac(J,u,p,t)\n    σ = p[1]\n    ρ = p[2]\n    β = p[3]\n    x = u[1]\n    y = u[2]\n    z = u[3]\n    J[1,1] = -σ\n    J[2,1] = ρ - z\n    J[3,1] = y\n    J[1,2] = σ\n    J[2,2] = -1\n    J[3,2] = x\n    J[1,3] = 0\n    J[2,3] = -x\n    J[3,3] = -β\nend\n\nfunction lorenz_tgrad(J,u,p,t)\n    nothing\nend\n\nfunc = ODEFunction(lorenz,jac=lorenz_jac,tgrad=lorenz_tgrad)\nprob_jac = ODEProblem(func,u0,tspan,p)\nmonteprob_jac = EnsembleProblem(prob_jac, prob_func = prob_func)\n\n@time solve(monteprob_jac,Rodas5(),EnsembleGPUArray(),dt=0.1,trajectories=10_000,saveat=1.0f0)\n@time solve(monteprob_jac,TRBDF2(),EnsembleGPUArray(),dt=0.1,trajectories=10_000,saveat=1.0f0)","category":"page"},{"location":"#DiffEqGPU:-Massively-Data-Parallel-GPU-Solving-of-ODEs","page":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","title":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","text":"","category":"section"},{"location":"","page":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","title":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","text":"This library is a component package of the DifferentialEquations.jl ecosystem. It includes functionality for making use of GPUs in the differential equation solvers.","category":"page"},{"location":"#The-two-ways-to-accelerate-ODE-solvers-with-GPUs","page":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","title":"The two ways to accelerate ODE solvers with GPUs","text":"","category":"section"},{"location":"","page":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","title":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","text":"There are two very different ways that one can accelerate an ODE solution with GPUs. There is one case where u is very big and f is very expensive but very structured, and you use GPUs to accelerate the computation of said f. The other use case is where u is very small but you want to solve the ODE f over many different initial conditions (u0) or parameters p. In that case, you can use GPUs to parallelize over different parameters and initial conditions. In other words:","category":"page"},{"location":"","page":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","title":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","text":"Type of Problem SciML Solution\nAccelerate a big ODE Use CUDA.jl's CuArray as u0\nSolve the same ODE with many u0 and p Use DiffEqGPU.jl's EnsembleGPUArray and EnsembleGPUKernel","category":"page"},{"location":"#Example-of-Within-Method-GPU-Parallelism","page":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","title":"Example of Within-Method GPU Parallelism","text":"","category":"section"},{"location":"","page":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","title":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","text":"using OrdinaryDiffEq, CUDA, LinearAlgebra\nu0 = cu(rand(1000))\nA  = cu(randn(1000,1000))\nf(du,u,p,t)  = mul!(du,A,u)\nprob = ODEProblem(f,u0,(0.0f0,1.0f0)) # Float32 is better on GPUs!\nsol = solve(prob,Tsit5())","category":"page"},{"location":"#Example-of-Parameter-Parallelism-with-GPU-Ensemble-Methods","page":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","title":"Example of Parameter-Parallelism with GPU Ensemble Methods","text":"","category":"section"},{"location":"","page":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","title":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","text":"using DiffEqGPU, OrdinaryDiffEq, StaticArrays\n\nfunction lorenz(u, p, t)\n    σ = p[1]\n    ρ = p[2]\n    β = p[3]\n    du1 = σ * (u[2] - u[1])\n    du2 = u[1] * (ρ - u[3]) - u[2]\n    du3 = u[1] * u[2] - β * u[3]\n    return SVector{3}(du1, du2, du3)\nend\n\nu0 = @SVector [1.0f0; 0.0f0; 0.0f0]\ntspan = (0.0f0, 10.0f0)\np = @SVector [10.0f0, 28.0f0, 8 / 3.0f0]\nprob = ODEProblem{false}(lorenz, u0, tspan, p)\nprob_func = (prob, i, repeat) -> remake(prob, p = (@SVector rand(Float32, 3)).*p)\nmonteprob = EnsembleProblem(prob, prob_func = prob_func, safetycopy = false)\n\n@time sol = solve(monteprob, GPUTsit5(), EnsembleGPUKernel(), trajectories = 10_000, adaptive = false, dt = 0.1f0)","category":"page"},{"location":"#Reproducibility","page":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","title":"Reproducibility","text":"","category":"section"},{"location":"","page":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","title":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","text":"<details><summary>The documentation of this SciML package was built using these direct dependencies,</summary>","category":"page"},{"location":"","page":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","title":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","text":"using Pkg # hide\nPkg.status() # hide","category":"page"},{"location":"","page":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","title":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","text":"</details>","category":"page"},{"location":"","page":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","title":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","text":"<details><summary>and using this machine and Julia version.</summary>","category":"page"},{"location":"","page":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","title":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","text":"using InteractiveUtils # hide\nversioninfo() # hide","category":"page"},{"location":"","page":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","title":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","text":"</details>","category":"page"},{"location":"","page":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","title":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","text":"<details><summary>A more complete overview of all dependencies and their versions is also provided.</summary>","category":"page"},{"location":"","page":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","title":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","text":"using Pkg # hide\nPkg.status(;mode = PKGMODE_MANIFEST) # hide","category":"page"},{"location":"","page":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","title":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","text":"</details>","category":"page"},{"location":"","page":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","title":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","text":"You can also download the\n<a href=\"","category":"page"},{"location":"","page":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","title":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","text":"using TOML\nversion = TOML.parse(read(\"../../Project.toml\",String))[\"version\"]\nname = TOML.parse(read(\"../../Project.toml\",String))[\"name\"]\nlink = \"https://github.com/SciML/\"*name*\".jl/tree/gh-pages/v\"*version*\"/assets/Manifest.toml\"","category":"page"},{"location":"","page":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","title":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","text":"\">manifest</a> file and the\n<a href=\"","category":"page"},{"location":"","page":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","title":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","text":"using TOML\nversion = TOML.parse(read(\"../../Project.toml\",String))[\"version\"]\nname = TOML.parse(read(\"../../Project.toml\",String))[\"name\"]\nlink = \"https://github.com/SciML/\"*name*\".jl/tree/gh-pages/v\"*version*\"/assets/Project.toml\"","category":"page"},{"location":"","page":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","title":"DiffEqGPU: Massively Data-Parallel GPU Solving of ODEs","text":"\">project</a> file.","category":"page"},{"location":"manual/ensemblegpuarray/#EnsembleGPUArray","page":"EnsembleGPUArray","title":"EnsembleGPUArray","text":"","category":"section"},{"location":"manual/ensemblegpuarray/#API","page":"EnsembleGPUArray","title":"API","text":"","category":"section"},{"location":"manual/ensemblegpuarray/","page":"EnsembleGPUArray","title":"EnsembleGPUArray","text":"EnsembleGPUArray\nEnsembleCPUArray","category":"page"},{"location":"manual/ensemblegpuarray/#DiffEqGPU.EnsembleGPUArray","page":"EnsembleGPUArray","title":"DiffEqGPU.EnsembleGPUArray","text":"EnsembleGPUArray(cpu_offload = 0.2)\n\nAn EnsembleArrayAlgorithm which utilizes the GPU kernels to parallelize each ODE solve with their separate ODE integrator on each kernel.\n\nPositional Arguments\n\ncpu_offload: the percentage of trajectories to offload to the CPU. Default is 0.2 or 20% of trajectories.\n\nLimitations\n\nEnsembleGPUArray requires being able to generate a kernel for f using KernelAbstractons.jl and solving the resulting ODE defined over CuArray input types. This introduces the following limitations on its usage:\n\nNot all standard Julia f functions are allowed. Only Julia f functions which are capable of being compiled into a GPU kernel are allowed. This notably means that certain features of Julia can cause issues inside of a kernel, like:\nAllocating memory (building arrays)\nLinear algebra (anything that calls BLAS)\nBroadcast\nNot all ODE solvers are allowed, only those from OrdinaryDiffEq.jl. The tested feature set from OrdinaryDiffEq.jl includes:\nExplicit Runge-Kutta methods\nImplicit Runge-Kutta methods\nRosenbrock methods\nDiscreteCallbacks and ContinuousCallbacks\nStiff ODEs require the analytical solution of every derivative function it requires. For example, Rosenbrock methods require the Jacobian and the gradient with respect to time, and so these two functions are required to be given. Note that they can be generated by the modelingtoolkitize approach.\nTo use multiple GPUs over clusters, one must manually setup one process per GPU. See the multi-GPU tutorial for more details.\n\nExample\n\nusing DiffEqGPU, OrdinaryDiffEq\nfunction lorenz(du,u,p,t)\n    du[1] = p[1]*(u[2]-u[1])\n    du[2] = u[1]*(p[2]-u[3]) - u[2]\n    du[3] = u[1]*u[2] - p[3]*u[3]\nend\n\nu0 = Float32[1.0;0.0;0.0]\ntspan = (0.0f0,100.0f0)\np = [10.0f0,28.0f0,8/3f0]\nprob = ODEProblem(lorenz,u0,tspan,p)\nprob_func = (prob,i,repeat) -> remake(prob,p=rand(Float32,3).*p)\nmonteprob = EnsembleProblem(prob, prob_func = prob_func, safetycopy=false)\n@time sol = solve(monteprob,Tsit5(),EnsembleGPUArray(),trajectories=10_000,saveat=1.0f0)\n\n\n\n\n\n","category":"type"},{"location":"manual/ensemblegpuarray/#DiffEqGPU.EnsembleCPUArray","page":"EnsembleGPUArray","title":"DiffEqGPU.EnsembleCPUArray","text":"EnsembleCPUArray(cpu_offload = 0.2)\n\nAn EnsembleArrayAlgorithm which utilizes the CPU kernels to parallelize each ODE solve with their separate ODE integrator on each kernel. This method is meant to be a debugging counterpart to EnsembleGPUArray, having the same behavior and using the same KernelAbstractions.jl process to build the combined ODE, but without the restrictions of f being a GPU-compatible kernel function.\n\nIt is unlikely that this method is useful beyond library development and debugging as almost any case should be faster with EnsembleThreads or EnsembleDistributed.\n\n\n\n\n\n","category":"type"}]
}
